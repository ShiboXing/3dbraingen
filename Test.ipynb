{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nilearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ebe258099fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mADNI_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBRATS_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nilearn'"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import nibabel as nib\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import dataloader\n",
    "\n",
    "from nilearn import plotting\n",
    "from ADNI_dataset import *\n",
    "from BRATS_dataset import *\n",
    "from ATLAS_dataset import *\n",
    "\n",
    "import pytorch_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = True\n",
    "workers = 4\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "Use_BRATS = False\n",
    "Use_ATLAS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ADNIdataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9afdd3c2e549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mADNIdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m train_loader = torch.utils.data.DataLoader(trainset,batch_size=BATCH_SIZE,\n\u001b[1;32m      3\u001b[0m                                           shuffle=True,num_workers=workers)\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#'flair' or 't2' or 't1ce'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBRATSdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flair'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ADNIdataset' is not defined"
     ]
    }
   ],
   "source": [
    "trainset = ADNIdataset(augmentation=True)\n",
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True,num_workers=workers)\n",
    "#'flair' or 't2' or 't1ce'\n",
    "trainset = BRATSdataset(imgtype='flair')\n",
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size = BATCH_SIZE, shuffle=True,\n",
    "                                               num_workers=workers)\n",
    "\n",
    "trainset = ATLASdataset(augmentation=True)\n",
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True,num_workers=workers)\n",
    "\n",
    "def inf_train_gen(data_loader):\n",
    "    while True:\n",
    "        for _,images in enumerate(data_loader):\n",
    "            yield images\n",
    "gen_load = inf_train_gen(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Generator Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-585ef7593a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#------------Trained Model of ATLAS dataset---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./checkpoint/Ours_G.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Ours (Alpha-WGAN-GP)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m# G.load_state_dict(torch.load('./checkpoint/Alpha_G.pth')) #Alpha-GAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# G.load_state_dict(torch.load('./checkpoint/VAEGAN_G.pth')) #VAE-GAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------\n",
    "#Choose the Model you want!\n",
    "from Model_alphaWGAN import Generator\n",
    "# from Model_alphaGAN import Generator\n",
    "# from Model_VAEGAN import Generator\n",
    "# from Model_WGAN import Generator\n",
    "#-------------------------------------------\n",
    "\n",
    "G = Generator(noise=1000).cuda()\n",
    "#-----------------------\n",
    "#Load Pre-trained model\n",
    "#-----------------------\n",
    "\n",
    "#------------Trained Model of ATLAS dataset---------------------\n",
    "G.load_state_dict(torch.load('./checkpoint/Ours_G.pth')) #Ours (Alpha-WGAN-GP)\n",
    "# G.load_state_dict(torch.load('./checkpoint/Alpha_G.pth')) #Alpha-GAN\n",
    "# G.load_state_dict(torch.load('./checkpoint/VAEGAN_G.pth')) #VAE-GAN\n",
    "# G.load_state_dict(torch.load('./checkpoint/WGAN_G.pth')) #WGAN-GP\n",
    "\n",
    "#------------Trained Model of ATLAS dataset---------------------\n",
    "# G.load_state_dict(torch.load('./checkpoint/Ours_at_G.pth'))\n",
    "\n",
    "#------------Trained Models of BRATS dataset---------------------\n",
    "# G.load_state_dict(torch.load('./checkpoint/Ours_fl_G.pth'))\n",
    "# G.load_state_dict(torch.load('./checkpoint/Ours_t2_G.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake Image - slice series visualization\n",
    "\n",
    "You can change the axis (x , y , z ) by changing  display_mode = 'x' / 'y' / 'z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_color = False\n",
    "\n",
    "noise = Variable(torch.randn((1, 1000)).cuda())\n",
    "fake_image = G(noise)\n",
    "featmask = np.squeeze(fake_image[0].data.cpu().numpy())\n",
    "featmask = nib.Nifti1Image(featmask,affine = np.eye(4))\n",
    "\n",
    "arr1 = [4,6,8,10,12,14,16,18,20,22,24,26,28,30,32]\n",
    "arr2 = [34,36,38,40,42,44,46,48,50,52,54,56,58,60]\n",
    "if Show_color:\n",
    "    disp = plotting.plot_img(featmask,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "    # disp.annotate(size=25,left_right=False,positions=True)\n",
    "    plotting.show()\n",
    "    disp=plotting.plot_img(featmask,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "    # disp.annotate(size=25,left_right=False)\n",
    "    plotting.show()\n",
    "else:\n",
    "    disp = plotting.plot_anat(featmask,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "    plotting.show()\n",
    "    # disp.annotate(size=25,left_right=False)\n",
    "    disp=plotting.plot_anat(featmask,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "    # disp.annotate(size=25,left_right=False)\n",
    "    plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake Image - Center cut slices Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Variable(torch.randn((1, 1000)).cuda())\n",
    "fake_image = G(noise)\n",
    "featmask = np.squeeze(fake_image[0].data.cpu().numpy())\n",
    "featmask = nib.Nifti1Image(featmask,affine = np.eye(4))\n",
    "plotting.plot_img(featmask,cut_coords=(32,32,32),draw_cross=False,annotate=False,black_bg=True)\n",
    "plotting.plot_anat(featmask,cut_coords=(32,32,32),draw_cross=False,annotate=False,black_bg=True)\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Image - Slice series visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Show_color = False\n",
    "\n",
    "image = gen_load.__next__()\n",
    "featmask = np.squeeze(image[0].data.cpu().numpy())\n",
    "featmask = nib.Nifti1Image(featmask,affine = np.eye(4))\n",
    "arr1 = [4,6,8,10,12,14,16,18,20,22,24,26,28,30,32]\n",
    "arr2 = [34,36,38,40,42,44,46,48,50,52,54,56,58,60]\n",
    "\n",
    "if Show_color:\n",
    "    disp = plotting.plot_img(featmask,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "    # disp.annotate(size=25,left_right=False,positions=True)\n",
    "    plotting.show()\n",
    "    disp=plotting.plot_img(featmask,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "    # disp.annotate(size=25,left_right=False)\n",
    "    plotting.show()\n",
    "else:\n",
    "    disp = plotting.plot_anat(featmask,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "    plotting.show()\n",
    "    # disp.annotate(size=25,left_right=False)\n",
    "    disp=plotting.plot_anat(featmask,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "    # disp.annotate(size=25,left_right=False)\n",
    "    plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS-SSIM Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ssim = 0\n",
    "for k in range(20):\n",
    "    for i,dat in enumerate(train_loader):\n",
    "        if len(dat)!=2:\n",
    "            break\n",
    "        img1 = dat[0]\n",
    "        img2 = dat[1]\n",
    "\n",
    "        msssim = pytorch_ssim.msssim_3d(img1,img2)\n",
    "        sum_ssim = sum_ssim+msssim\n",
    "    print(sum_ssim/((k+1)*(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ssim = 0\n",
    "for i in range(1000):\n",
    "    noise = Variable(torch.randn((2, 1000)).cuda())\n",
    "    fake_image = G(noise)\n",
    "\n",
    "    img1 = fake_image[0]\n",
    "    img2 = fake_image[1]\n",
    "\n",
    "    msssim = pytorch_ssim.msssim_3d(img1,img2)\n",
    "    sum_ssim = sum_ssim+msssim\n",
    "print(sum_ssim/1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum-Mean Discrepancy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in G.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "meanarr = []\n",
    "for s in range(100):\n",
    "    distmean = 0.0\n",
    "    for i,(y) in enumerate(train_loader):\n",
    "        y = Variable(y).cuda()\n",
    "        noise = Variable(torch.randn((y.size(0), 1000)).cuda())\n",
    "        x = G(noise)\n",
    "\n",
    "        B = y.size(0)\n",
    "        x = x.view(x.size(0), x.size(2) * x.size(3)*x.size(4))\n",
    "        y = y.view(y.size(0), y.size(2) * y.size(3)*y.size(4))\n",
    "\n",
    "        xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n",
    "\n",
    "        beta = (1./(B*B))\n",
    "        gamma = (2./(B*B)) \n",
    "\n",
    "        Dist = beta * (torch.sum(xx)+torch.sum(yy)) - gamma * torch.sum(zz)\n",
    "        distmean += Dist\n",
    "    print('Mean:'+str(distmean/(i+1)))\n",
    "    meanarr.append(distmean/(i+1))\n",
    "meanarr = numpy.array(meanarr)\n",
    "print('Total_mean:'+str(np.mean(meanarr))+' STD:'+str(np.std(meanarr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
